import cv2, pickle
import numpy as np
from skimage.feature import hog
from lesson_functions import bin_spatial, color_hist

# Original globals
color_space='YCrCb' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb
source_color_space='RGB' 
target_color_space='YCrCb' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb
orient         = 9  # HOG orientations
pix_per_cell   = 8  # HOG pixels per cell
cell_per_block = 2  # HOG cells per block
hog_channel  = "ALL" # HOG Channel 0, 1, 2, or "ALL"
spatial_size=(16,16) # Spatial binning dimensions
hist_bins    = 16    # Number of histogram bins
spatial_feat = True # Spatial features on or off
hist_feat    = True # Histogram features on or offy
hog_feat     = True # HOG features on or off

# Retrieve pickled Trained Classifiers
with open('./svcModel.pkl', 'rb') as fr: svc = pickle.load(fr)
with open('./X_scaler.pkl', 'rb') as rf: X_scaler = pickle.load(rf)

num_frames_to_keep  = 10 # no. of frames to keep
recent_hot_windows  = [] # list of hot windows identified on recent frames
recent_bbox_windows = [] # list of bounding boxes around cars

# Thresholds for heatmaps
thresh_high = 10
thresh_low  = 5
base_size   = 64

# searchWidnows: Areas of interest to be searched. The elements are :
#((xmin, xMax), (ymin, yMax)) 
# the coordiantes are relative to the image size, (i.e. between 0 and 1)
# search widnow size
GVsearchWindows = [ (np.array([[0.0,1.0], [0.5, 1.0]]), 64), 
                  (np.array([[0.0,1.0], [0.5, 1.0]]), 96),
                  (np.array([[0.0,1.0], [0.5, 1.0]]), 128),]

# dbg var: Frame Tracking while VideoFileClip Processing
frame_no = 0       # dbg var
max_heat_list = [] # dbg var

def extract_features(imgs, hog_feat_list=[], 
                        source_color_space='RGB', 
                        target_color_space='YCrCb',
                        spatial_size=(32, 32),
                        hist_bins=32, orient=9, 
                        pix_per_cell=8, cell_per_block=2, hog_channel=[1],
                        spatial_feat=True, hist_feat=True, hog_feat=True):    
    '''
    Extract features from a list of images
    hog_feat_list: len=0 or len=len(imgs); passed on hog features for the images in the list
    source_color_space: expected color space of the image
    target_color_space: target color space of the image
    spatial size: passed to bin_spatial()
    hist_bins: passed to color_hist()
    pix_per_cell, cell_per_block, orient: passed to get_hog_features()
    hog_channel: array indicating the channel numbers of the target_color_space
    spatial_feat: if True calls bin_spatial()
    hist_feat: if True calls color_hist() 
    hog_feat: if True calls get_hog_features()
    '''    
    # Create a list to append feature vectors to
    all_images_features = []
    # Iterate through the list of images
    for idx, image in enumerate(imgs):
        single_image_features = []
        
        # Convert image if to the target color space        
        if source_color_space != target_color_space:
            color_space_change_code = eval('cv2.COLOR_'+source_color_space+'2'+target_color_space)
            feature_image = cv2.cvtColor(image, color_space_change_code)
        else: 
            feature_image = np.copy(image)      
         
        # Extract spatial features
        if spatial_feat == True:
            spatial_features = bin_spatial(feature_image, size=spatial_size)
            single_image_features.append(spatial_features)
        # Extract color features in histogram form RGB image
        if hist_feat == True:
            hist_features = color_hist(feature_image, nbins=hist_bins)
            single_image_features.append(hist_features)
        # Extract hog features
        if hog_feat == True:
            # Check to see if hog features have been passed along to the function
            # If yes, then just append to the features, if not obtain hog features from scratch
            if len(hog_feat_list)==0:
                # Initialize hog_features 
                hog_features=[]
                resized_img = cv2.resize(feature_image, (base_size, base_size))
                # Check for the image channel to be passed on to hog_features function
                if hog_channel == 'ALL': channelS = [0,1,2,]
                else: channelS  = [hog_channel]
                for channel in channelS:
                    hog_features.append(get_hog_features(resized_img[:,:,channel], 
                                        orient, pix_per_cell, cell_per_block, 
                                        vis=False, feature_vec=True))
                # Ravel all hog features
                hog_features = np.concatenate(hog_features).ravel()
                # Append the new feature vector to the features list
                single_image_features.append(hog_features)
                #print(len(single_image_features),len(single_image_features[-1]), single_image_features[-1][-1].shape)
            else:
                single_image_features.append(hog_feat_list[idx])
        
        all_images_features.append(np.concatenate(single_image_features).ravel())
    # Return list of feature vectors
    return all_images_features

def extract_hog_features_once(img, search_window, window_list, source_color_space='RGB', target_color_space='YCrCb',
                              orient=9, pix_per_cell=8, cell_per_block=2, hog_channel=[1]):
    '''
    Extract hog features for the area of interest only once, and return the relevant hog features 
    for each window in window_list. This will speed up the processing of images during production
    img: image that is being processed
    search_window: the area of the image that is being searched: (np.array([[xmin,xmax], [ymin, ymax]]), window_size)
                   xmin, xmax, ymin and ymax are in fractions of image size
    window_list: list of windows that are passd on
    source_color_space: expected color space of the image
    target_color_space: target color space of the image
    pix_per_cell, cell_per_block, orient: passed to get_hog_features()
    hog_channel: array indicating the channel numbers of the target_color_space
    '''
    # Calculate the scaled image size given the size of the search windows and the base_size
    scaled_size = (round(base_size/search_window[1]*img.shape[1]), round(base_size/search_window[1]*img.shape[0]))
    # resize image
    img_scaled = cv2.resize(img, scaled_size)
    # Calculate the coordinates of the region of interest
    x_start_stop = ((search_window[0][0]*img_scaled.shape[1]).round()).astype(int)
    y_start_stop = ((search_window[0][1]*img_scaled.shape[0]).round()).astype(int)
    feature_img = img_scaled[y_start_stop[0]:y_start_stop[1], x_start_stop[0]:x_start_stop[1]]
    
    # Convert to the target color space
    if source_color_space != target_color_space:
        color_space_change_code = eval('cv2.COLOR_'+source_color_space+'2'+target_color_space)
        feature_image = cv2.cvtColor(feature_img, color_space_change_code)
    else: 
        feature_image = np.copy(feature_img)      
     
    # Initialize hog_features 
    hog_features=[]
    # Check for the image channel to be passed on to hog_features function
    if hog_channel == 'ALL': channelS = [0,1,2,]
    else: channelS  = [hog_channel]
    for channel in channelS:
        hog_features.append(get_hog_features(feature_image[:,:,channel], 
                            orient, pix_per_cell, cell_per_block, 
                            vis=False, feature_vec=False))
    # create feat_list to store features for all windows in the window_list    
    feat_list = []
    # Iterate through all windows in widnow_list and extract the hog features pertaining to that window
    for window in window_list:
        # Adjust the window coordiantes based on the re-sizing and clipping of the image that was done previously
        new_window = ((window[0][0]*img_scaled.shape[1]/img.shape[1]-x_start_stop[0], 
                       window[0][1]*img_scaled.shape[0]/img.shape[0]-y_start_stop[0]), 
                      (window[1][0]*img_scaled.shape[1]/img.shape[1]-x_start_stop[0], 
                       window[1][1]*img_scaled.shape[0]/img.shape[0]-y_start_stop[0]))
        hog_window = ((max(round(new_window[0][0]/pix_per_cell),0),
                        max(round(new_window[0][1]/pix_per_cell),0)),
                      (max(round(new_window[1][0]/pix_per_cell)-(cell_per_block-1),0),
                        max(round(new_window[1][1]/pix_per_cell)-(cell_per_block-1),0)))
        # append current window featres together        
        cur_window_feat_list = []
        for item in hog_features:
            cur_window_feat_list.append(np.concatenate(item[hog_window[0][1]:hog_window[1][1],
                                                            hog_window[0][0]:hog_window[1][0],:,:,:]).ravel())
        # ravel the result and append to the feat_lsit
        feat_list.append(np.ravel(cur_window_feat_list))
    
    return feat_list

def get_hog_features(img, orient, pix_per_cell, cell_per_block, 
                        vis=False, feature_vec=True):
    '''
    Return hog features and visuatlization
    img: image to be processed
    orient: orientation bins (parameter to hog function)
    pix_per_call: (parameter to hog function)
    cells_per_block: (paramter to hog function)
    vis: visualize (paremter to hog function)
    feature_vec: feature_vector (parameter to hog function)
    '''
    # Call with two outputs if vis==True
    if vis == True:
        features, hog_image = hog(img, orientations=orient, 
                                  pixels_per_cell=(pix_per_cell, pix_per_cell),
                                  cells_per_block=(cell_per_block, cell_per_block), 
                                  transform_sqrt=True, 
                                  visualise=vis, feature_vector=feature_vec)
        return features, hog_image
    # Otherwise call with one output
    else:      
        features = hog(img, orientations=orient, 
                       pixels_per_cell=(pix_per_cell, pix_per_cell),
                       cells_per_block=(cell_per_block, cell_per_block), 
                       transform_sqrt=True, 
                       visualise=vis, feature_vector=feature_vec)
        return features
